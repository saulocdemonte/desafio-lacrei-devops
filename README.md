# Desafio T√©cnico ‚Äì DevOps na Lacrei Sa√∫de

Reposit√≥rio contendo a solu√ß√£o para o desafio t√©cnico de DevOps da Lacrei Sa√∫de. Este projeto implementa um pipeline de CI/CD para o deploy automatizado de uma aplica√ß√£o Node.js em um ambiente de staging na AWS.

## üöÄ Tecnologias Utilizadas

- **Aplica√ß√£o:** Node.js com Express.js
- **Containeriza√ß√£o:** Docker
- **Cloud:** AWS (EC2)
- **CI/CD:** GitHub Actions
- **Controle de Vers√£o:** Git & GitHub

---

## ‚öôÔ∏è 1. Setup do Ambiente de Staging

O ambiente de staging foi configurado na AWS utilizando o servi√ßo EC2. O objetivo √© ter um servidor dedicado para testes que simule o ambiente de produ√ß√£o.

As especifica√ß√µes da inst√¢ncia s√£o:

- **Provedor Cloud:** AWS
- **Regi√£o:** `us-east-1` (Norte da Virg√≠nia)
- **Servi√ßo:** EC2 (Elastic Compute Cloud)
- **Nome da Inst√¢ncia:** `lacrei-staging-server`
- **AMI (Sistema Operacional):** Ubuntu Server 22.04 LTS
- **Tipo de Inst√¢ncia:** `t2.micro` (Qualificada para o n√≠vel gratuito)
- **Chave de Acesso:** `lacrei-devops-key.pem` foi gerada para garantir acesso administrativo seguro via SSH.
- **Security Group (Firewall):** Foi criado um grupo de seguran√ßa (`lacrei-webserver-sg`) com regras de entrada (`inbound rules`) para permitir tr√°fego nas seguintes portas:
  - **Porta 22 (SSH):** Para acesso administrativo remoto.
  - **Porta 80 (HTTP):** Para acesso web √† aplica√ß√£o.
  - **Porta 443 (HTTPS):** Reservada para a futura implementa√ß√£o de certificado SSL/TLS.

---

## üîÑ 2. Fluxo de CI/CD

O pipeline de Integra√ß√£o e Entrega Cont√≠nua (CI/CD) foi implementado utilizando **GitHub Actions**. O objetivo √© automatizar todo o processo, desde o envio do c√≥digo at√© a implanta√ß√£o da aplica√ß√£o no ambiente de staging.

O fluxo de trabalho est√° definido no arquivo `.github/workflows/deploy-staging.yml` e √© executado da seguinte forma:

1.  **Gatilho (Trigger):** O pipeline √© acionado automaticamente a cada `push` de c√≥digo na branch `main` do reposit√≥rio.

2.  **Inicializa√ß√£o do Ambiente:** O GitHub Actions provisiona uma m√°quina virtual tempor√°ria (runner) com `ubuntu-latest` para executar as etapas da automa√ß√£o.

3.  **Checkout do C√≥digo:** O c√≥digo-fonte do projeto √© baixado do reposit√≥rio para a m√°quina virtual do runner.

4.  **Login no Docker Hub:** O pipeline se autentica de forma segura no Docker Hub, utilizando um `username` e um `token` de acesso armazenados como GitHub Secrets (`DOCKERHUB_USERNAME` e `DOCKERHUB_TOKEN`).

5.  **Build e Push da Imagem:** A imagem Docker da aplica√ß√£o √© constru√≠da a partir do `Dockerfile`. Ap√≥s o build, essa imagem √© marcada com a tag `latest` e enviada (`push`) para o reposit√≥rio no Docker Hub.

6.  **Deploy no Servidor EC2:** O passo final conecta-se via SSH ao servidor de staging na AWS, utilizando as credenciais armazenadas nos GitHub Secrets (`AWS_HOST`, `AWS_USERNAME`, `AWS_SSH_KEY`). No servidor, ele executa um script que realiza as seguintes a√ß√µes:
    * Baixa a imagem mais recente do Docker Hub (`docker pull`).
    * Para o cont√™iner da vers√£o antiga, caso esteja em execu√ß√£o (`docker stop`).
    * Remove o cont√™iner antigo (`docker rm`).
    * Inicia um novo cont√™iner com a imagem atualizada, mapeando a porta 80 (HTTP) do servidor para a porta 3000 da aplica√ß√£o (`docker run`).

Este fluxo garante que qualquer atualiza√ß√£o no c√≥digo da branch `main` seja refletida no ambiente de staging em poucos minutos, sem qualquer interven√ß√£o manual.

---

## ‚ö†Ô∏è 3. Registro de Erros e Decis√µes Tomadas

Durante a configura√ß√£o do ambiente e do pipeline, diversos desafios foram encontrados. A documenta√ß√£o a seguir detalha os principais problemas e as solu√ß√µes aplicadas.

#### 1. Pol√≠tica de Execu√ß√£o do PowerShell
- **Problema:** Ao tentar verificar a vers√£o do NPM com `npm -v`, o PowerShell bloqueou a execu√ß√£o do script, retornando um erro de pol√≠tica de seguran√ßa.
- **Solu√ß√£o:** A pol√≠tica de execu√ß√£o do PowerShell foi alterada para `RemoteSigned` atrav√©s do comando `Set-ExecutionPolicy RemoteSigned`, executado em um terminal com privil√©gios de administrador. Esta decis√£o permitiu a execu√ß√£o de scripts locais necess√°rios para o desenvolvimento, mantendo a seguran√ßa contra scripts n√£o assinados da internet.

#### 2. `node_modules` no Controle de Vers√£o
- **Problema:** Na primeira tentativa de versionamento, a pasta `node_modules` (contendo milhares de depend√™ncias) foi acidentalmente adicionada √† √°rea de prepara√ß√£o do Git.
- **Solu√ß√£o:** Foi criado um arquivo `.gitignore` na raiz do projeto para instruir o Git a ignorar a pasta `/node_modules`. Para corrigir a √°rea de prepara√ß√£o, foi necess√°rio usar o comando `git rm -rf --cached .` para limpar o cache do Git e depois um novo `git add .` para adicionar apenas os arquivos relevantes.

#### 3. Permiss√µes da Chave SSH no Windows
- **Problema:** O cliente SSH se recusou a usar o arquivo `.pem` para conectar √† inst√¢ncia EC2, retornando um erro de "permiss√µes muito abertas" (`UNPROTECTED PRIVATE KEY FILE!`). Ap√≥s uma tentativa de corre√ß√£o, o erro mudou para `Permission denied`.
- **Solu√ß√£o:** Foi necess√°rio um ajuste fino nas permiss√µes de seguran√ßa do arquivo `.pem` no Windows. Utilizando a interface de propriedades do arquivo, a heran√ßa de permiss√µes foi desabilitada, e todas as entidades de seguran√ßa foram removidas, exceto o usu√°rio atual, que recebeu permiss√£o de "Controle total". Isso garantiu que apenas o propriet√°rio do arquivo pudesse l√™-lo, satisfazendo a exig√™ncia do SSH.

#### 4. Erro `Cannot GET /` Ap√≥s o Deploy
- **Problema:** Ap√≥s o primeiro deploy bem-sucedido, acessar o IP do servidor no navegador resultava na mensagem `Cannot GET /`.
- **Solu√ß√£o:** O diagn√≥stico revelou que n√£o era um erro de deploy, mas sim de acesso √† rota incorreta. A aplica√ß√£o foi desenvolvida para responder apenas no endpoint `/status`. A solu√ß√£o foi acessar a URL completa (`http://<IP_DO_SERVIDOR>/status`), que validou o sucesso da implanta√ß√£o.

#### 5. Falha no Pipeline de CI/CD Ap√≥s Mudan√ßa de IP
- **Problema:** Ap√≥s a transi√ß√£o de um IP din√¢mico para um IP Fixo (El√°stico), o pipeline de CI/CD come√ßou a falhar consistentemente na etapa de deploy. O log de erro indicava um `i/o timeout` na conex√£o SSH para a porta 22.
- **Solu√ß√£o:** A investiga√ß√£o mostrou que o segredo `AWS_HOST` nas configura√ß√µes do reposit√≥rio GitHub ainda continha o endere√ßo de IP din√¢mico antigo. O pipeline estava tentando se conectar a um endere√ßo que n√£o era mais v√°lido. A solu√ß√£o foi atualizar o valor do segredo `AWS_HOST` com o novo IP El√°stico (`35.153.92.36`). Ap√≥s a atualiza√ß√£o, o pipeline foi re-executado e completado com sucesso.

---

## ‚è™ 4. Processo de Rollback

A estrat√©gia de rollback adotada para este projeto utiliza a funcionalidade nativa do GitHub Actions para re-executar um workflow bem-sucedido anterior.

#### Passos para o Rollback Manual:

1.  **Identificar o Deploy Est√°vel:** Navegue at√© a aba **`Actions`** do reposit√≥rio no GitHub. Na lista de execu√ß√µes de workflow, identifique a √∫ltima execu√ß√£o que foi conclu√≠da com sucesso (com um check verde ‚úÖ) e que corresponde √† vers√£o est√°vel que se deseja restaurar.

2.  **Re-executar o Workflow:** Clique nesta execu√ß√£o para ver seus detalhes. No canto superior direito da tela de detalhes, clique no bot√£o **`Re-run all jobs`**.

3.  **Confirma√ß√£o:** O GitHub Actions iniciar√° uma nova execu√ß√£o do pipeline, mas utilizando exatamente o mesmo c√≥digo-fonte (o mesmo commit) daquela vers√£o anterior est√°vel.

4.  **Resultado:** Ao final da execu√ß√£o, o pipeline ter√° reconstru√≠do a imagem Docker da vers√£o antiga, a enviado para o Docker Hub com a tag `latest` e a implantado no servidor EC2. Isso efetivamente substitui a vers√£o defeituosa pela √∫ltima vers√£o est√°vel conhecida.

#### Proposta de Futura Melhoria (Rollback Avan√ßado)

Uma abordagem mais r√°pida e robusta, ideal para ambientes de produ√ß√£o, seria aprimorar o pipeline para criar tags de imagem Docker versionadas (ex: usando a hash do commit Git, como `saulodemonte/desafio-lacrei-app:a1b2c3d`).

Com isso, o rollback seria quase instant√¢neo, executado diretamente no servidor via SSH, sem a necessidade de um novo build, seguindo os passos:

```bash
# 1. Conectar-se ao servidor EC2 via SSH

# 2. Parar e remover o cont√™iner atual
docker stop lacrei-container && docker rm lacrei-container

# 3. Iniciar o cont√™iner com a tag da vers√£o est√°vel anterior
docker run -d -p 80:3000 --name lacrei-container saulodemonte/desafio-lacrei-app:<hash_do_commit_estavel>

``` 
---

## üõ°Ô∏è 5. Checklist de Seguran√ßa Aplicado

As seguintes medidas de seguran√ßa foram implementadas neste projeto para garantir a integridade do ambiente e a prote√ß√£o de dados sens√≠veis, conforme solicitado no desafio.

- **Gerenciamento de Segredos (Secrets Management):**
  - Todas as credenciais sens√≠veis ‚Äî chaves de acesso da AWS, a chave SSH para o servidor EC2 e o token de acesso do Docker Hub ‚Äî **n√£o** foram escritas diretamente no c√≥digo (`hardcoded`).
  - Em vez disso, foram armazenadas de forma segura como **GitHub Secrets** criptografados. O pipeline de CI/CD acessa essas credenciais apenas em tempo de execu√ß√£o, garantindo que elas n√£o fiquem expostas no reposit√≥rio de c√≥digo.

- **Firewall de Rede (AWS Security Group):**
  - A inst√¢ncia EC2 est√° protegida por um *Security Group* que atua como um firewall virtual.
  - O acesso de rede foi configurado seguindo o **princ√≠pio do menor privil√©gio**, permitindo tr√°fego de entrada (`inbound`) apenas nas portas estritamente necess√°rias:
    - `Porta 22 (SSH)`: Para acesso administrativo remoto.
    - `Porta 80 (HTTP)`: Para acesso p√∫blico √† aplica√ß√£o web.
    - `Porta 443 (HTTPS)`: Reservada para a futura implementa√ß√£o de tr√°fego seguro.

- **Autentica√ß√£o Segura ao Servidor (SSH Key Pair):**
  - O acesso ao terminal do servidor EC2 n√£o √© feito por senha, mas sim por um **par de chaves criptogr√°ficas (SSH Key Pair)**.
  - A chave privada (`.pem`) √© mantida em posse do desenvolvedor, garantindo que apenas entidades autorizadas possam acessar o servidor.

- **Pr√≥ximos Passos de Seguran√ßa (Propostas):**
  - **HTTPS/TLS:** Implementar um certificado SSL/TLS (ex: via Let's Encrypt) para criptografar todo o tr√°fego entre o cliente e o servidor.
  - **Usu√°rio IAM Dedicado:** Criar um usu√°rio IAM na AWS com permiss√µes m√≠nimas e espec√≠ficas para as necessidades do pipeline, em vez de usar chaves de um usu√°rio com privil√©gios mais amplos.

  ---

## üëÅÔ∏è 6. Observabilidade (Logs e Monitoramento)

Para garantir que a aplica√ß√£o possa ser monitorada e que seus registros de eventos sejam persistentes e acess√≠veis, foram implementadas estrat√©gias de logging centralizado e alertas proativos.

### Logging Centralizado com CloudWatch

- **Problema Inicial:** Por padr√£o, os logs gerados pela aplica√ß√£o (`console.log`) existiriam apenas dentro do cont√™iner Docker, sendo perdidos sempre que o cont√™iner fosse reiniciado ou substitu√≠do.

- **Solu√ß√£o Implementada:**
  1.  **Permiss√µes (IAM Role):** Foi criada uma IAM Role (`EC2-CloudWatch-Logs-Role`) com a pol√≠tica `CloudWatchLogsFullAccess` e associada √† inst√¢ncia EC2, concedendo a ela a permiss√£o necess√°ria para enviar logs ao CloudWatch.
  2.  **Configura√ß√£o do Docker:** O daemon do Docker no servidor foi configurado para utilizar o driver de log `awslogs`, direcionando os logs para a regi√£o `us-east-1`.
  3.  **Pipeline de Deploy:** O comando `docker run` no pipeline (`deploy-staging.yml`) foi atualizado para incluir flags expl√≠citas de logging, garantindo que o cont√™iner envie seus logs para o grupo de logs **`lacrei-staging-logs`** no CloudWatch.

- **Resultado:** Todos os logs da aplica√ß√£o agora s√£o transmitidos em tempo real e armazenados de forma segura e persistente no AWS CloudWatch, cumprindo o requisito de "logs acess√≠veis".

### Monitoramento e Alertas Proativos (B√¥nus)

Para complementar a observabilidade, foi implementado um sistema de alertas proativos para monitorar a sa√∫de da inst√¢ncia EC2, cumprindo um dos itens b√¥nus.

- **Ferramentas:** AWS CloudWatch Alarms e AWS SNS (Simple Notification Service).
- **Implementa√ß√£o:**
  1.  **Canal de Notifica√ß√£o (SNS):** Foi criado um T√≥pico SNS (`lacrei-alarms`) e uma assinatura de email foi configurada e confirmada para servir como canal de notifica√ß√£o.
  2.  **Alarme (CloudWatch):** Foi criado um Alarme no CloudWatch (`Alarme_CPU_Alta_Staging`) para monitorar a m√©trica `CPUUtilization` da inst√¢ncia.
  3.  **Regra:** O alarme foi configurado para disparar caso a m√©dia de uso da CPU ultrapasse **70%** por um per√≠odo cont√≠nuo de **5 minutos**.
  4.  **A√ß√£o:** Ao ser disparado, o alarme envia uma notifica√ß√£o para o T√≥pico SNS, que por sua vez encaminha um alerta para o email inscrito.
- **Resultado:** O ambiente agora conta com um monitoramento proativo que notifica a equipe sobre poss√≠veis problemas de performance, permitindo uma a√ß√£o r√°pida antes que os usu√°rios sejam impactados.

---

## üí∞ B√¥nus: Proposta de Integra√ß√£o com Asaas

Esta se√ß√£o descreve uma arquitetura proposta para integrar a aplica√ß√£o com o sistema de pagamentos Asaas, cumprindo o item b√¥nus do desafio. A integra√ß√£o permitiria que a plataforma processasse pagamentos de forma automatizada.

O fluxo de trabalho seria o seguinte:

#### 1. Cria√ß√£o da Cobran√ßa (Client -> Nosso Servidor -> Asaas)
- O cliente, na interface da aplica√ß√£o, iniciaria um processo de pagamento.
- O frontend enviaria uma requisi√ß√£o para um novo endpoint no nosso backend (ex: `POST /api/pagamentos`).
- Nosso servidor, ao receber a requisi√ß√£o, faria uma chamada segura (server-to-server) para a API da Asaas, enviando os dados do cliente e da cobran√ßa.
- A Asaas processaria a requisi√ß√£o, geraria a cobran√ßa (seja por cart√£o de cr√©dito, Pix ou boleto) e retornaria um ID de pagamento e/ou um link para nosso servidor.
- Nosso servidor salvaria o ID da transa√ß√£o em seu banco de dados e retornaria o link de pagamento para o cliente finalizar a opera√ß√£o.

#### 2. Notifica√ß√£o de Pagamento (Asaas -> Nosso Servidor via Webhook)
- Para saber quando o pagamento foi efetivamente confirmado (especialmente em casos de boleto), configurar√≠amos um **Webhook** na plataforma da Asaas.
- Apontar√≠amos este webhook para um endpoint espec√≠fico da nossa API (ex: `POST /webhook/asaas/confirmacao`).
- Quando um pagamento fosse confirmado, a Asaas enviaria uma notifica√ß√£o autom√°tica para este endpoint.
- Nossa API receberia a notifica√ß√£o, validaria sua autenticidade e atualizaria o status do pagamento no nosso banco de dados, liberando o servi√ßo para o cliente.

#### Considera√ß√µes de Seguran√ßa
- Toda a comunica√ß√£o com a API da Asaas seria feita via HTTPS.
- A chave de API da Asaas seria armazenada de forma segura como um **GitHub Secret** (`ASAAS_API_KEY`) e injetada na aplica√ß√£o como uma vari√°vel de ambiente, nunca sendo exposta no c√≥digo-fonte.