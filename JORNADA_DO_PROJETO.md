# Jornada do Projeto: Um Guia Passo a Passo

Este documento detalha a jornada completa de constru√ß√£o da solu√ß√£o para o Desafio DevOps da Lacrei Sa√∫de, servindo como um tutorial e um registro de aprendizado de todo o processo.

---

### **Etapa 1: Funda√ß√£o e Teste Local**

#### Objetivo:
O objetivo inicial foi criar a "mat√©ria-prima" do projeto: uma aplica√ß√£o Node.js funcional e as instru√ß√µes para sua containeriza√ß√£o com Docker. Antes de qualquer automa√ß√£o ou implanta√ß√£o na nuvem, era crucial garantir que a aplica√ß√£o pudesse ser constru√≠da e executada de forma padronizada e isolada no ambiente de desenvolvimento local.

#### Conceitos Chave:
- **Node.js:** Ambiente de execu√ß√£o para o c√≥digo JavaScript do lado do servidor.
- **Express.js:** Framework minimalista para Node.js, utilizado para criar a API e a rota `/status`.
- **Docker:** Plataforma de containeriza√ß√£o que "empacota" a aplica√ß√£o e todas as suas depend√™ncias em uma unidade isolada e port√°til chamada cont√™iner.
- **Dockerfile:** Um arquivo de texto que cont√©m a "receita", o passo a passo de comandos para o Docker construir a imagem da nossa aplica√ß√£o.

#### Passo a Passo Executado:
1.  **Estrutura do Projeto:** Foi criada uma pasta local para o projeto.
2.  **Defini√ß√£o da Aplica√ß√£o (`package.json`):** Criei o arquivo para definir os metadados do projeto e declarar a depend√™ncia do `express`.
3.  **C√≥digo-Fonte (`app.js`):** Implementei um servidor web simples com uma √∫nica rota `GET /status` para atender ao requisito do desafio.
4.  **Instru√ß√µes de Containeriza√ß√£o (`Dockerfile`):** Criei o `Dockerfile` definindo a imagem base (`node:18-alpine`), copiando os arquivos necess√°rios, instalando as depend√™ncias com `npm install` e definindo o comando de inicializa√ß√£o (`CMD`).
5.  **Valida√ß√£o Local:**
    - A aplica√ß√£o foi testada nativamente com o comando `node app.js`.
    - A imagem Docker foi constru√≠da com `docker build -t desafio-lacrei-app .`.
    - O cont√™iner foi executado com `docker run -p 3000:3000 ...` e a aplica√ß√£o foi validada atrav√©s do navegador, confirmando o sucesso da containeriza√ß√£o.

### **Etapa 2: Versionamento e Publica√ß√£o do C√≥digo**

#### Objetivo:
Com a aplica√ß√£o funcionando localmente, o pr√≥ximo passo foi mover o c√≥digo para um sistema de controle de vers√£o e hosped√°-lo em um reposit√≥rio remoto. Isso foi fundamental para rastrear o hist√≥rico de altera√ß√µes e, principalmente, para servir como ponto de partida para o futuro pipeline de CI/CD.

#### Conceitos Chave:
- **Git:** Sistema de controle de vers√£o distribu√≠do, que usei para gerenciar o hist√≥rico do c√≥digo-fonte.
- **GitHub:** Plataforma de hospedagem para reposit√≥rios Git, que tamb√©m prov√™ as ferramentas de automa√ß√£o (GitHub Actions).
- **Reposit√≥rio (Local e Remoto):** O reposit√≥rio local (na pasta `.git`) vive na minha m√°quina, enquanto o remoto (no GitHub) serve como um backup centralizado e ponto de integra√ß√£o.
- **`.gitignore`:** Um arquivo de configura√ß√£o que instrui o Git sobre quais arquivos e pastas devem ser ignorados (como a pasta `node_modules`).

#### Passo a Passo Executado:
1.  **Inicializa√ß√£o do Reposit√≥rio Local:** Executei o comando `git init` na pasta do projeto para criar o reposit√≥rio local.
2.  **Cria√ß√£o do `.gitignore`:** Criei um arquivo `.gitignore` com a entrada `/node_modules` para evitar o versionamento de milhares de arquivos de depend√™ncias.
3.  **Resolu√ß√£o de Problemas:** Foi necess√°rio um processo de debug para limpar a *staging area* do Git, que havia capturado a `node_modules` acidentalmente antes da cria√ß√£o do `.gitignore`. Usei os comandos `git reset` e `git rm -rf --cached .` para corrigir o estado do versionamento.
4.  **Cria√ß√£o do Reposit√≥rio Remoto:** Criei um novo reposit√≥rio p√∫blico e vazio diretamente na interface do GitHub.
5.  **Primeiro Commit:** Adicionei os arquivos do projeto (`git add .`) e os salvei no hist√≥rico local com o comando `git commit`.
6.  **Conex√£o e Envio:** Conectei o reposit√≥rio local ao remoto com `git remote add origin ...` e enviei o c√≥digo pela primeira vez ao GitHub com `git push -u origin main`.

### **Etapa 3: Cria√ß√£o do Ambiente de Staging na AWS**

#### Objetivo:
O objetivo desta etapa foi provisionar a infraestrutura de nuvem para o primeiro ambiente (Staging). Criei um servidor virtual na AWS que seria o destino dos deploys automatizados, garantindo um local isolado e padronizado para os testes da aplica√ß√£o.

#### Conceitos Chave:
- **AWS (Amazon Web Services):** Provedor de servi√ßos de nuvem que utilizei para hospedar a infraestrutura.
- **EC2 (Elastic Compute Cloud):** Servi√ßo da AWS que fornece capacidade computacional redimension√°vel (m√°quinas virtuais) na nuvem.
- **Inst√¢ncia:** Uma m√°quina virtual individual no ambiente EC2.
- **AMI (Amazon Machine Image):** O template de software (neste caso, `Ubuntu Server 22.04 LTS`) que usei para lan√ßar a inst√¢ncia.
- **Security Group:** Um firewall virtual que controla o tr√°fego para a inst√¢ncia. Configurei-o para permitir acesso nas portas `22` (SSH), `80` (HTTP) e `443` (HTTPS).
- **SSH (Secure Shell) e Key Pair:** O m√©todo de conex√£o segura para administrar o servidor remotamente. Em vez de senhas, utilizei um par de chaves criptogr√°ficas (`.pem`) para a autentica√ß√£o.
- **IP El√°stico:** Um endere√ßo de IP est√°tico e fixo, que aloquei para garantir que o endere√ßo do servidor n√£o mudasse ap√≥s reinicializa√ß√µes.

#### Passo a Passo Executado:
1.  **Provisionamento da Inst√¢ncia:** Pelo console da AWS, lancei uma nova inst√¢ncia EC2 `t2.micro` com uma AMI do Ubuntu Server 22.04 LTS na regi√£o `us-east-1`.
2.  **Configura√ß√£o de Seguran√ßa:** Criei e baixei um novo par de chaves (`lacrei-devops-key.pem`) para o acesso SSH. Criei um Security Group (`lacrei-webserver-sg`), configurando as regras de firewall para as portas necess√°rias.
3.  **Conex√£o e Resolu√ß√£o de Problemas:** Realizei a primeira conex√£o via SSH. Foi necess√°rio ajustar as permiss√µes do arquivo `.pem` no Windows, que por padr√£o eram muito abertas, para satisfazer os requisitos de seguran√ßa do cliente SSH.
4.  **Prepara√ß√£o do Servidor:** Ap√≥s conectar, instalei o Docker Engine na inst√¢ncia (`docker.io`) e adicionei o usu√°rio `ubuntu` ao grupo `docker` para poder executar comandos sem `sudo`.
5.  **Cria√ß√£o do IP Fixo:** Para garantir um endere√ßo est√°vel, aloquei um IP El√°stico e o associei √† inst√¢ncia de staging.

### **Etapa 4: Automa√ß√£o do Deploy em Staging (CI/CD)**

#### Objetivo:
O objetivo desta etapa foi criar um "rob√¥" (o pipeline de CI/CD) para automatizar completamente o processo de entrega da aplica√ß√£o. A meta era que, a cada nova altera√ß√£o enviada ao reposit√≥rio, a aplica√ß√£o fosse automaticamente constru√≠da, empacotada e implantada no servidor de staging, eliminando a necessidade de qualquer interven√ß√£o manual.

#### Conceitos Chave:
- **CI/CD (Continuous Integration/Continuous Deployment):** A pr√°tica de automatizar as fases de constru√ß√£o, teste e implanta√ß√£o de software.
- **GitHub Actions:** A plataforma de automa√ß√£o nativa do GitHub que utilizei para construir o pipeline.
- **Workflow:** O processo automatizado, definido em um arquivo de configura√ß√£o no formato YAML (`.github/workflows/deploy-staging.yml`).
- **GitHub Secrets:** O "cofre" seguro do reposit√≥rio, onde armazenei todas as credenciais sens√≠veis (como as chaves da AWS) para que o pipeline pudesse us√°-las sem exp√¥-las no c√≥digo.
- **GitHub Container Registry (GHCR):** O registro de cont√™ineres nativo do GitHub. Optei por us√°-lo para hospedar as imagens Docker, o que simplificou e tornou a autentica√ß√£o mais segura.

#### Passo a Passo Executado:
1.  **Cria√ß√£o dos Segredos:** Configurei os GitHub Secrets necess√°rios para a automa√ß√£o: `AWS_HOST` (IP do servidor), `AWS_USERNAME` (usu√°rio `ubuntu`) e `AWS_SSH_KEY` (a chave privada `.pem`).
2.  **Cria√ß√£o do Arquivo de Workflow:** Criei a estrutura de pastas `.github/workflows/` e o arquivo `deploy-staging.yml`.
3.  **Defini√ß√£o do Pipeline:** Estruturei o pipeline com os seguintes passos:
    - **Gatilho:** O pipeline seria acionado a cada `push` na branch `main`.
    - **Build & Push:** A imagem Docker seria constru√≠da e enviada para um registro de cont√™ineres.
    - **Deploy:** O pipeline se conectaria via SSH ao servidor de staging para baixar a nova imagem e reiniciar o cont√™iner.
4.  **Resolu√ß√£o de Problemas de Autentica√ß√£o (Decis√£o Estrat√©gica):**
    - **Problema:** A tentativa inicial de usar o Docker Hub como registro de cont√™ineres encontrou um erro persistente e raro de `insufficient_scope`, mesmo com um token de acesso configurado corretamente.
    - **Solu√ß√£o:** Tomei a decis√£o estrat√©gica de abandonar o Docker Hub e migrar para o **GitHub Container Registry (GHCR)**. Esta abordagem se provou superior, pois a autentica√ß√£o √© feita de forma nativa e autom√°tica com o `GITHUB_TOKEN`, eliminando a necessidade de gerenciar tokens de terceiros e resolvendo o problema de permiss√£o de uma vez por todas.
5.  **Sucesso do Pipeline:** Ap√≥s a migra√ß√£o para o GHCR, o pipeline de staging foi executado com sucesso, automatizando o deploy do in√≠cio ao fim.

### **Etapa 5: Implementa√ß√£o de Seguran√ßa (HTTPS)**

#### Objetivo:
O objetivo desta etapa foi adicionar uma camada de seguran√ßa essencial √† aplica√ß√£o, implementando o protocolo HTTPS. Isso garante que toda a comunica√ß√£o entre o navegador do usu√°rio e o servidor seja criptografada, eliminando o aviso de "N√£o seguro" do navegador e protegendo os dados em tr√¢nsito, um requisito obrigat√≥rio do desafio.

#### Conceitos Chave:
- **HTTPS (Hypertext Transfer Protocol Secure):** A vers√£o segura do protocolo HTTP, que utiliza criptografia SSL/TLS.
- **SSL/TLS:** Certificados digitais que autenticam a identidade de um site e permitem a comunica√ß√£o criptografada.
- **Let's Encrypt:** Uma Autoridade Certificadora (CA) gratuita e automatizada que usei para obter os certificados SSL/TLS.
- **Certbot:** O software cliente que instalei no servidor para solicitar, gerenciar e renovar automaticamente os certificados da Let's Encrypt.
- **DuckDNS:** Um servi√ßo de DNS din√¢mico gratuito, que utilizei para obter um nome de dom√≠nio (`.duckdns.org`) e apont√°-lo para o IP Fixo do servidor.
- **Docker Volumes (`-v`):** Um recurso do Docker que permite "espelhar" uma pasta do servidor para dentro do cont√™iner. Foi crucial para dar √† aplica√ß√£o Node.js acesso aos arquivos de certificado.
- **Vari√°veis de Ambiente (`-e`):** Utilizadas para passar informa√ß√µes de configura√ß√£o para a aplica√ß√£o dentro do cont√™iner, tornando o c√≥digo mais flex√≠vel e reutiliz√°vel entre ambientes.

#### Passo a Passo Executado:
1.  **Configura√ß√£o do Dom√≠nio:** Criei um subdom√≠nio no DuckDNS (`saulo-devops-lacrei.duckdns.org`) e o apontei para o IP El√°stico do servidor de staging.
2.  **Gera√ß√£o do Certificado:** Conectei-me ao servidor via SSH e utilizei o Certbot no modo `standalone` para gerar os certificados SSL para o dom√≠nio. Para isso, foi necess√°rio parar temporariamente o cont√™iner da aplica√ß√£o para liberar a porta 80 para o processo de valida√ß√£o.
3.  **Refatora√ß√£o da Aplica√ß√£o (`app.js`):** Modifiquei o c√≥digo da aplica√ß√£o para que ela se tornasse configur√°vel. Ela passou a ler o nome do dom√≠nio de uma vari√°vel de ambiente (`DOMAIN_NAME`) para encontrar os arquivos de certificado corretos. Al√©m disso, criei dois servidores: um HTTPS na porta `8443` para a aplica√ß√£o principal e um servidor HTTP na porta `3000` com a √∫nica fun√ß√£o de redirecionar todo o tr√°fego para HTTPS.
4.  **Atualiza√ß√£o do Pipeline:** Modifiquei o `deploy-staging.yml` para habilitar o HTTPS no cont√™iner:
    - Adicionei o mapeamento de portas `-p 443:8443` (HTTPS) e `-p 80:3000` (HTTP Redirect).
    - Adicionei um volume com a flag `-v /etc/letsencrypt:/etc/letsencrypt:ro` para dar √† aplica√ß√£o acesso de leitura aos certificados.
    - Adicionei a vari√°vel de ambiente com a flag `-e DOMAIN_NAME=...` para informar √† aplica√ß√£o qual certificado carregar.
5.  **Valida√ß√£o:** Ap√≥s o deploy bem-sucedido, confirmei que o acesso ao dom√≠nio via `https://` exibia o cadeado de seguran√ßa (üîí) no navegador.

### **Etapa 6: Cria√ß√£o do Ambiente de Produ√ß√£o**

#### Objetivo:
O objetivo foi criar um segundo ambiente na AWS, totalmente isolado do de staging, para servir como o ambiente de **Produ√ß√£o**. Isso cumpre um requisito central do desafio e simula um fluxo de trabalho real, onde novas funcionalidades s√£o testadas em staging antes de serem promovidas para o ambiente dos usu√°rios finais.

#### Conceitos Chave:
- **M√∫ltiplos Ambientes:** Pr√°tica fundamental em DevOps para separar os est√°gios de desenvolvimento, teste (Staging) e uso real (Produ√ß√£o), garantindo estabilidade e seguran√ßa.
- **Reutiliza√ß√£o de Recursos:** Para manter a consist√™ncia e a efici√™ncia, reutilizei recursos sempre que poss√≠vel, como o **Par de Chaves SSH** e o **Security Group**, que j√° estavam configurados corretamente.
- **Otimiza√ß√£o de Custos:** Foi feita uma an√°lise de custos sobre o uso de um segundo IP Fixo (El√°stico). Para cumprir o desafio sem gerar cobran√ßas, optei por usar o IP p√∫blico din√¢mico para a inst√¢ncia de produ√ß√£o, com a estrat√©gia de mant√™-la em execu√ß√£o durante o per√≠odo de avalia√ß√£o.

#### Passo a Passo Executado:
1.  **Lan√ßamento da Inst√¢ncia:** Pelo console da AWS, lancei uma nova inst√¢ncia EC2 (`lacrei-production-server`), usando as mesmas configura√ß√µes base da de staging (`t2.micro`, Ubuntu 22.04 LTS).
2.  **Reutiliza√ß√£o de Configura√ß√µes:** Durante a cria√ß√£o, em vez de gerar novos recursos, selecionei o Par de Chaves (`lacrei-devops-key.pem`) e o Security Group (`lacrei-webserver-sg`) j√° existentes.
3.  **Obten√ß√£o do IP Din√¢mico:** Ap√≥s a inst√¢ncia entrar no estado `Running`, anotei seu IP p√∫blico din√¢mico para ser usado na configura√ß√£o do dom√≠nio e do pipeline.
4.  **Prepara√ß√£o do Servidor:** Assim como no de staging, conectei-me √† nova inst√¢ncia via SSH e realizei a instala√ß√£o e configura√ß√£o do Docker Engine.

### **Etapa 7: Automa√ß√£o do Deploy em Produ√ß√£o**

#### Objetivo:
O objetivo foi criar um segundo pipeline de CI/CD, dedicado exclusivamente ao ambiente de produ√ß√£o. Este pipeline precisava ser mais controlado e seguro que o de staging, garantindo que apenas vers√µes de c√≥digo est√°veis e explicitamente aprovadas fossem liberadas para os usu√°rios finais.

#### Conceitos Chave:
- **Gatilho por Tag (Git Tags):** Diferente do pipeline de staging que dispara a cada `push` na branch `main`, optei por um gatilho baseado em tags do Git (ex: `v1.0.0`, `v1.0.1`). Criar uma tag √© um ato intencional, que funciona como uma "autoriza√ß√£o" formal para o deploy em produ√ß√£o.
- **Versionamento de Imagens (Image Tagging):** Para garantir a rastreabilidade e facilitar poss√≠veis rollbacks, a imagem Docker enviada para o GHCR √© marcada com a mesma vers√£o da tag do Git (ex: `ghcr.io/saulocdemonte/desafio-lacrei-app:v1.0.1`), em vez de usar a tag gen√©rica `:latest`.

#### Passo a Passo Executado:
1.  **Configura√ß√£o do Segredo:** Criei um novo segredo no GitHub, `AWS_HOST_PROD`, para armazenar o endere√ßo IP do servidor de produ√ß√£o.
2.  **Cria√ß√£o do Dom√≠nio e Certificado:** Criei um novo dom√≠nio de produ√ß√£o no DuckDNS (`saulo-prod-lacrei.duckdns.org`) e, conectado ao servidor de produ√ß√£o, gerei um novo certificado SSL com o Certbot para este dom√≠nio.
3.  **Cria√ß√£o do Workflow de Produ√ß√£o:** Criei o arquivo `.github/workflows/deploy-production.yml`.
4.  **Customiza√ß√£o do Pipeline:** Adaptei o pipeline com as seguintes l√≥gicas espec√≠ficas para produ√ß√£o:
    - Alterei o gatilho (`on:`) para responder apenas a `push` de `tags` no formato `v*.*.*`.
    - Atualizei o passo de 'Build e Push' para usar a vari√°vel `${{ github.ref_name }}` do GitHub Actions, garantindo que a tag da imagem Docker fosse a mesma da tag do Git.
    - Apontei o passo de deploy para o servidor de produ√ß√£o, usando o segredo `AWS_HOST_PROD`.
    - Configurei o comando `docker run` para usar o HTTPS e a vari√°vel de ambiente `DOMAIN_NAME` espec√≠fica da produ√ß√£o.
5.  **Teste do Deploy:** Para testar, executei os comandos `git tag v1.0.x` e `git push origin v1.0.x`, o que acionou o pipeline com sucesso e implantou a aplica√ß√£o no ambiente de produ√ß√£o.

### **Etapa 8: Implementa√ß√£o da Observabilidade**

#### Objetivo:
O objetivo foi cumprir o requisito de observabilidade, garantindo que os logs gerados pela aplica√ß√£o fossem capturados, centralizados e armazenados de forma persistente. Isso √© essencial para monitorar a sa√∫de da aplica√ß√£o, analisar eventos e diagnosticar problemas sem precisar acessar o servidor diretamente.

#### Conceitos Chave:
- **Observabilidade:** Em DevOps, √© a capacidade de entender o estado interno de um sistema a partir de seus outputs externos (neste caso, os logs).
- **AWS CloudWatch Logs:** Um servi√ßo da AWS para armazenamento e monitoramento centralizado de arquivos de log.
- **IAM Role para EC2:** Uma forma segura de conceder permiss√µes a uma inst√¢ncia EC2 para acessar outros servi√ßos da AWS (como o CloudWatch) sem precisar armazenar chaves de acesso permanentes na m√°quina.
- **Docker Log Driver:** Um mecanismo que permite ao Docker redirecionar os logs dos cont√™ineres para diferentes destinos. Utilizei o driver `awslogs`.

#### Passo a Passo Executado:
1.  **Concess√£o de Permiss√µes (IAM Role):** Criei uma IAM Role (`EC2-CloudWatch-Logs-Role`) com a pol√≠tica `CloudWatchLogsFullAccess`. Em seguida, associei esta role a ambas as inst√¢ncias EC2 (staging e produ√ß√£o), concedendo-lhes a permiss√£o necess√°ria para enviar logs para o CloudWatch.
2.  **Configura√ß√£o do Docker no Servidor:** Conectei-me a cada servidor via SSH e criei o arquivo `/etc/docker/daemon.json` para configurar o `awslogs` como o driver de log padr√£o.
3.  **Atualiza√ß√£o dos Pipelines:** Para tornar a configura√ß√£o mais robusta, adicionei flags expl√≠citas de logging (`--log-driver` e `--log-opt`) ao comando `docker run` em ambos os arquivos de workflow (`.yml`), especificando o grupo de logs `lacrei-staging-logs`.
4.  **Resolu√ß√£o de Problemas:** O pipeline inicialmente falhou porque a IAM Role n√£o havia sido associada √† inst√¢ncia. Ap√≥s identificar e corrigir este passo, o deploy seguinte funcionou perfeitamente.
5.  **Valida√ß√£o:** Verifiquei o sucesso da implementa√ß√£o acessando o servi√ßo CloudWatch no console da AWS, localizando o grupo de logs e confirmando que as mensagens de inicializa√ß√£o da minha aplica√ß√£o estavam sendo registradas.

### **Etapa 9: Configura√ß√£o de Alertas (B√¥nus)**

#### Objetivo:
Para cumprir um dos itens b√¥nus e adicionar uma camada de monitoramento proativo, o objetivo foi criar um sistema de alertas autom√°ticos. A meta era ser notificado por email caso o servidor de staging apresentasse sinais de sobrecarga, permitindo uma a√ß√£o corretiva antes que o servi√ßo fosse impactado.

#### Conceitos Chave:
- **Monitoramento Proativo:** A pr√°tica de monitorar a sa√∫de de um sistema e gerar alertas autom√°ticos sobre poss√≠veis problemas, em vez de reagir apenas quando uma falha ocorre.
- **AWS CloudWatch Alarms:** O servi√ßo da AWS que permite criar "alarmes" que vigiam uma m√©trica espec√≠fica (como uso de CPU) e disparam a√ß√µes quando certas condi√ß√µes s√£o atendidas.
- **AWS SNS (Simple Notification Service):** Um servi√ßo de mensagens e notifica√ß√µes da AWS. Utilizei-o para criar um "T√≥pico" (um canal de notifica√ß√µes) para onde os alertas s√£o enviados.
- **M√©trica (`CPUUtilization`):** A m√©trica espec√≠fica do CloudWatch que mede a porcentagem de utiliza√ß√£o da CPU da inst√¢ncia EC2.

#### Passo a Passo Executado:
1.  **Cria√ß√£o do Canal de Notifica√ß√£o (SNS Topic):** No console do SNS, criei um T√≥pico Padr√£o chamado `lacrei-alarms`.
2.  **Cria√ß√£o da Assinatura (SNS Subscription):** Criei uma "assinatura" para este t√≥pico, utilizando o protocolo `Email` e cadastrando meu endere√ßo de email pessoal como o destino (`Endpoint`). Foi necess√°rio confirmar a inscri√ß√£o atrav√©s de um link enviado ao email.
3.  **Cria√ß√£o do Alarme (CloudWatch Alarm):** No console do CloudWatch, criei um novo alarme.
4.  **Defini√ß√£o da M√©trica e Condi√ß√£o:** Configurei o alarme para monitorar a m√©trica `CPUUtilization` da inst√¢ncia de staging. A condi√ß√£o definida foi: disparar o alarme se a m√©dia de uso da CPU for **maior que 70%** por um per√≠odo cont√≠nuo de **5 minutos**.
5.  **Configura√ß√£o da A√ß√£o:** Configurei o alarme para, quando entrar no estado `In alarm`, enviar uma notifica√ß√£o para o T√≥pico SNS `lacrei-alarms`.
6.  **Valida√ß√£o:** Confirmei que o alarme foi criado com sucesso e apareceu na lista de alarmes, passando do estado inicial de "Dados insuficientes" para "OK".

### **Etapa 10: Finaliza√ß√£o com Testes e Documenta√ß√£o**

#### Objetivo:
O objetivo da etapa final foi garantir a confiabilidade dos pipelines e consolidar todo o trabalho em uma documenta√ß√£o coesa e profissional. Isso incluiu a implementa√ß√£o de um teste de valida√ß√£o automatizado (conforme o requisito do desafio) e a cria√ß√£o dos documentos finais do projeto.

#### Conceitos Chave:
- **Smoke Test (Teste de Fuma√ßa):** Um tipo de teste simples e r√°pido executado ap√≥s um deploy para verificar se as fun√ß√µes mais cr√≠ticas da aplica√ß√£o est√£o funcionando. No nosso caso, o teste valida se o servidor web est√° no ar e respondendo na rota `/status`.
- **`curl`:** Uma ferramenta de linha de comando para fazer requisi√ß√µes web. Utilizei a flag `-f` (fail), que faz o comando falhar se o servidor responder com um erro HTTP (como 404 ou 500), o que automaticamente falharia o pipeline.
- **Documenta√ß√£o T√©cnica (`README.md`):** O arquivo que serve como a porta de entrada e o manual principal do projeto.

#### Passo a Passo Executado:
1.  **Implementa√ß√£o do Smoke Test:** Adicionei um novo passo chamado "Validar Deploy" ao final de ambos os workflows (`deploy-staging.yml` e `deploy-production.yml`).
2.  **Configura√ß√£o do Teste:** O passo executa um `sleep 15` para aguardar a inicializa√ß√£o do cont√™iner, seguido por um `curl -f` que acessa a URL `/status` de cada ambiente respectivo (Staging ou Produ√ß√£o). O sucesso deste passo confirma que o deploy n√£o apenas foi executado, mas resultou em uma aplica√ß√£o funcional e acess√≠vel.
3.  **Finaliza√ß√£o da Documenta√ß√£o Principal:** Realizei a cria√ß√£o e revis√£o completa do arquivo `README.md` do reposit√≥rio, garantindo que todas as se√ß√µes obrigat√≥rias e b√¥nus do desafio fossem preenchidas com informa√ß√µes precisas, refletindo o estado final do projeto.
4.  **Cria√ß√£o deste Documento (`JORNADA_DO_PROJETO.md`):** Como um passo final de excel√™ncia, criei este documento para servir como um tutorial detalhado e um registro de aprendizado de toda a jornada, desde a concep√ß√£o at√© a entrega final, demonstrando a capacidade de documentar processos complexos.

---

### **Etapa 11: Procedimento de Limpeza (Cleanup)**

#### Objetivo:
A etapa final, ap√≥s a conclus√£o e avalia√ß√£o do projeto, √© remover (descomissionar) todos os recursos provisionados na AWS para garantir a otimiza√ß√£o de custos e a seguran√ßa, evitando cobran√ßas futuras.

#### Passo a Passo para Remo√ß√£o Segura:

1.  **Terminar as Inst√¢ncias EC2:**
    - Navegar at√© o painel do EC2.
    - Selecionar as inst√¢ncias `lacrei-staging-server` e `lacrei-production-server`.
    - Clicar em `Instance state` > `Terminate instance`. A a√ß√£o "Terminate" apaga permanentemente as m√°quinas virtuais.

2.  **Liberar os Endere√ßos IP El√°sticos:**
    - No painel do EC2, ir para a se√ß√£o `Elastic IPs`.
    - Selecionar os dois IPs Fixos que foram alocados.
    - Clicar em `Actions` > `Release Elastic IP addresses`.

3.  **Excluir o Par de Chaves (Key Pair):**
    - No painel do EC2, ir para a se√ß√£o `Key Pairs`.
    - Selecionar a chave `lacrei-devops-key` e exclu√≠-la.

4.  **Excluir o Grupo de Seguran√ßa (Security Group):**
    - No painel do EC2, ir para a se√ß√£o `Security Groups`.
    - Selecionar o grupo `lacrei-webserver-sg` e exclu√≠-lo.

5.  **Excluir a Fun√ß√£o IAM (IAM Role):**
    - Navegar at√© o servi√ßo **IAM**.
    - Ir para `Roles` (Fun√ß√µes), selecionar a `EC2-CloudWatch-Logs-Role` e exclu√≠-la.

6.  **Excluir Recursos de Observabilidade:**
    - Navegar at√© o servi√ßo **CloudWatch**.
    - Em `Logs` > `Log groups`, selecionar `lacrei-staging-logs` e exclu√≠-lo.
    - Em `Alarms` > `All alarms`, selecionar `Alarme_CPU_Alta_Staging` e exclu√≠-lo.
    - Navegar at√© o servi√ßo **SNS**.
    - Em `Topics`, selecionar `lacrei-alarms` e exclu√≠-lo.

    A execu√ß√£o destes passos garante que todos os recursos criados para o projeto sejam removidos, evitando qualquer cobran√ßa futura na conta da AWS.